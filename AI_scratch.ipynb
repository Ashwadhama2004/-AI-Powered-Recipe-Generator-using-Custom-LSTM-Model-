{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'title', 'ingredients', 'directions', 'link', 'source',\n",
      "       'NER'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset= pd.read_csv(\"RecipeNLG_dataset.csv\")\n",
    "dataset.head()\n",
    "print(dataset.columns)  # Check available columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Labels: [0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Keep only relevant columns\n",
    "dataset = dataset[['ingredients', 'directions']].dropna()\n",
    "\n",
    "# Convert to lowercase\n",
    "dataset[\"ingredients\"] = dataset[\"ingredients\"].str.lower()\n",
    "dataset[\"directions\"] = dataset[\"directions\"].str.lower()\n",
    "\n",
    "# Remove special characters\n",
    "dataset[\"ingredients\"] = dataset[\"ingredients\"].apply(lambda x: re.sub(r\"[^a-zA-Z0-9, ]\", \"\", x))\n",
    "dataset[\"directions\"] = dataset[\"directions\"].apply(lambda x: re.sub(r\"[^a-zA-Z0-9, ]\", \"\", x))\n",
    "\n",
    "# Format dataset for text generation\n",
    "dataset[\"input_text\"] = \"Ingredients: \" + dataset[\"ingredients\"]\n",
    "dataset[\"target_text\"] = \"Directions: \" + dataset[\"directions\"]\n",
    "\n",
    "# Train-validation split\n",
    "train_data, val_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save cleaned datasets\n",
    "train_data.to_csv(\"train_data.csv\", index=False)\n",
    "val_data.to_csv(\"val_data.csv\", index=False)\n",
    "\n",
    "print(\"âœ… Data Preprocessing Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text processing completed! âœ…\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def safe_join(lst):\n",
    "    return \" \".join(lst) if isinstance(lst, list) else \"\"\n",
    "\n",
    "# Convert ingredients and directions into single strings\n",
    "train_data[\"ingredients\"] = train_data[\"ingredients\"].apply(safe_join)\n",
    "train_data[\"directions\"] = train_data[\"directions\"].apply(safe_join)\n",
    "\n",
    "# Convert ingredients and directions into single strings for validation data\n",
    "val_data[\"ingredients\"] = val_data[\"ingredients\"].apply(safe_join)\n",
    "val_data[\"directions\"] = val_data[\"directions\"].apply(safe_join)\n",
    "\n",
    "# Convert ingredients and directions into a single text per recipe\n",
    "train_texts = train_data.apply(lambda x: f\"{x['ingredients']} {x['directions']}\", axis=1).tolist()\n",
    "val_texts = val_data.apply(lambda x: f\"{x['ingredients']} {x['directions']}\", axis=1).tolist()\n",
    "\n",
    "\n",
    "overlap = set(train_texts) & set(val_texts)\n",
    "print(f\"Tokenized Text Overlap: {len(overlap)}\")  \n",
    "\n",
    "\n",
    "print(\"Text processing completed! âœ…\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization completed!\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load TinyBERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"huawei-noah/TinyBERT_General_4L_312D\")\n",
    "\n",
    "# Tokenize train texts\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=64)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=64)\n",
    "\n",
    "print(\"Tokenization completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TinyBERT model with regularization loaded! ðŸš€\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Load TinyBERT for classification\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"huawei-noah/TinyBERT_General_4L_312D\",\n",
    "    num_labels=10,  \n",
    "    hidden_dropout_prob=0.5,  # Increase dropout\n",
    "    attention_probs_dropout_prob=0.5  # Dropout for attention layers\n",
    ")\n",
    "\n",
    "# Freeze some TinyBERT layers to reduce overfitting\n",
    "for param in model.bert.parameters():\n",
    "    param.requires_grad = False  # Freeze base TinyBERT layers\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "print(\"TinyBERT model with regularization loaded! ðŸš€\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ready!\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Load T5 tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "\n",
    "class RecipeDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.input_texts = data[\"input_text\"].tolist()\n",
    "        self.target_texts = data[\"target_text\"].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_enc = tokenizer(self.input_texts[idx], padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "        target_enc = tokenizer(self.target_texts[idx], padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": input_enc[\"input_ids\"].squeeze(),\n",
    "            \"attention_mask\": input_enc[\"attention_mask\"].squeeze(),\n",
    "            \"labels\": target_enc[\"input_ids\"].squeeze()\n",
    "        }\n",
    "\n",
    "# Load dataset\n",
    "train_dataset = RecipeDataset(train_data)\n",
    "val_dataset = RecipeDataset(val_data)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "print(\"âœ… Data Loaded for Training!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "print(\"Dataloader ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function & optimizer set up!\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "\n",
    "# Define loss function\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Learning rate scheduler\n",
    "num_training_steps = len(train_loader) * 3  # Assuming 3 epochs\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "print(\"Loss function & optimizer set up!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [19:54<00:00,  4.19it/s, loss=1.03] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Validation Loss: 0.6246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [17:35<00:00,  4.74it/s, loss=0.162]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Validation Loss: 0.1584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [18:48<00:00,  4.43it/s, loss=0.0911] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Validation Loss: 0.0949\n",
      "Training completed! âœ…\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW, get_scheduler\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load T5 model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\").to(device)\n",
    "\n",
    "# Optimizer & Scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "num_training_steps = len(train_loader) * 3  # Assuming 3 epochs\n",
    "lr_scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 3\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "\n",
    "    for batch in loop:\n",
    "        batch = {key: val.to(device) for key, val in batch.items()}\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        loop.set_description(f\"Epoch {epoch+1}\")\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = {key: val.to(device) for key, val in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            total_val_loss += outputs.loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    print(f\"Epoch {epoch+1} | Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # Save best model\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), \"best_t5_model.pth\")\n",
    "\n",
    "print(\"âœ… Training Completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for batch in train_loader:\n",
    "        batch = {key: val.to(device) for key, val in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "\n",
    "        # Get predictions\n",
    "        predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "        correct += (predictions == batch[\"labels\"]).sum().item()\n",
    "        total += batch[\"labels\"].size(0)\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:  # Use validation set\n",
    "        batch = {key: val.to(device) for key, val in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "\n",
    "        predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "        correct += (predictions == batch[\"labels\"]).sum().item()\n",
    "        total += batch[\"labels\"].size(0)\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Test with a sample ingredient list\u001b[39;00m\n\u001b[0;32m     17\u001b[0m ingredients \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchicken, garlic, onions, tomatoes, salt, pepper\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 18\u001b[0m recipe \u001b[38;5;241m=\u001b[39m generate_recipe(ingredients)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated Recipe:\u001b[39m\u001b[38;5;124m\"\u001b[39m, recipe)\n",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m, in \u001b[0;36mgenerate_recipe\u001b[1;34m(ingredients)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_recipe\u001b[39m(ingredients):\n\u001b[1;32m----> 2\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Format input\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     input_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIngredients: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m ingredients\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "def generate_recipe(ingredients):\n",
    "    model.eval()\n",
    "    \n",
    "    # Format input\n",
    "    input_text = \"Ingredients: \" + ingredients\n",
    "    input_enc = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Generate output\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(**input_enc, max_length=150)\n",
    "    \n",
    "    # Decode output\n",
    "    recipe = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return recipe\n",
    "\n",
    "# Test with a sample ingredient list\n",
    "ingredients = \"chicken, garlic, onions, tomatoes, salt, pepper\"\n",
    "recipe = generate_recipe(ingredients)\n",
    "print(\"Generated Recipe:\", recipe)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trainy2_O",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
